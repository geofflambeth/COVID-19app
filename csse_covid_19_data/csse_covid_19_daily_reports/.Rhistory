install.packages("swirl")
library("swirl")
swirl()
bye()
#'Build DIMA Template Files
#'@description Build a file in the format needed for DIMA
#'@param template.file An Excel of a blank DIMA template
#'@param method The file template method. Options are "LPI", "Richness", "Gap".
#'@param data The data output from xlsx2R.
#'@param  out.file The file path for the output
#'@name dima.template
#'@return A \code {tbl} of files formated for a DIMA template.
#'@export
#'@rdname dima.template
#Read DIMA.template file
build.DIMA.template<-function(data, template.file, method, out.file){
#If it is a line based method, fix a few other field names
if(method %in% c("LPI", "Gap")){
#Read DIMA template
DIMA.template<-readxl::read_excel(template.file, col_types = "text")
#Template names
template.names<-names(DIMA.template)
#Update the LPI Template Names (e.g., remove spaces)
names(DIMA.template)<-names(DIMA.template) %>% gsub(pattern=" ", replacement = "")
#Fix Date field so it is R friendly
DIMA.template<-dplyr::rename(DIMA.template, "Date"="Date(mm/dd/yyyy)")
DIMA.template<-dplyr::rename(DIMA.template, "LineLength"="LineLength(m)", "InterceptInterval"="InterceptInterval(m)")
#Join to data
data.formatted<-dplyr::full_join(DIMA.template, data)
#Subset to fields in DIMA template
data.formatted<-data.formatted[, colnames(data.formatted) %in% colnames(DIMA.template)]
#Add the Excel formatted names back in
names(data.formatted)<-template.names
openxlsx::write.xlsx(x = data.formatted, file = out.file)
}
#If this is the method
if(method %in% "Richness"){
###Build DIMA Header Table
DIMA.template.header<-readxl::read_excel(template.file, col_types = "text", sheet = "SpecRich SubPlots")
#Template names
template.names.header<-names(DIMA.template.header)
#Update the  Template Names (e.g., remove spaces)
names(DIMA.template.header)<-names(DIMA.template.header) %>% gsub(pattern=" ", replacement = "")
#Join to data
data.formatted.header<-dplyr::full_join(DIMA.template.header, data,
by=c(`SubPlot#`="SubPlot.", colnames(data)[colnames(data) %in% colnames(DIMA.template.header)]))
#Subset to fields in DIMA template
data.formatted.header<-data.formatted.header[,colnames(data.formatted.header) %in% colnames(DIMA.template.header)]
#Add the Excel formatted names back in
names(data.formatted.header)<-template.names.header
###Build DIMA Detail Table
DIMA.template.detail<-readxl::read_excel(template.file, col_types = "text", sheet = "SubPlot Species")
#Template names
template.names.detail<-names(DIMA.template.detail)
#Update the  Template Names (e.g., remove spaces)
names(DIMA.template.detail)<-names(DIMA.template.detail) %>% gsub(pattern=" ", replacement = "")
#Join to data
data.formatted.detail<-dplyr::full_join(DIMA.template.detail, data,
by=c(`SubPlot#`="SubPlot.", colnames(data)[colnames(data) %in% colnames(DIMA.template.detail)]))
#Subset to fields in DIMA template
data.formatted.detail<-data.formatted.detail[, colnames(data.formatted.detail) %in% colnames(DIMA.template.detail)]
#Add the Excel formatted names back in
names(data.formatted.detail)<-template.names.detail
#Create list
data.formatted<-list("SpecRich SubPlots"=data.formatted.header, "SubPlot Species"=data.formatted.detail)
#Write out detail table
openxlsx::write.xlsx(x = data.formatted, file=out.file)
}
}
#'@export
#'@rdname dima.template
#'Import from legacy excel files
#'@description Import legacy data from Excel files
#'@param excel.file An Excel of a blank DIMA template
#'@param format Format type, as identified in the reference lookup table
#'@param reference Reference lookup table filepath which identifies excel file formats and corresponding field map
#'@name legacy.format
#'@return A \code {tbl} of all method data in a directory formatted for joining to the DIMA.template.
#'@export
#'@rdname legacy.format
#'
#Make reference tall format
reference.tall<-function(reference){
#Read reference file
reference<-read.csv(reference, stringsAsFactors = FALSE)
#Gather Reference tall
reference.tall<-reference %>% tidyr::gather(key=format, value=cell.ref, -Table, -FieldName)
return(reference.tall)
}
#'@export
#'@rdname legacy.format
#Map excel references to a given field name, given a specific reference table
map.excel<-function(excel.file, reference.tall, field, format){
cell.ref<-reference.tall$cell.ref[reference.tall$FieldName==field &reference.tall$format==format] %>% as.character() %>% strsplit(.,split=",")%>% unlist() %>% gsub("\ ", "", .)
#Check to see if it is a valid excel reference
if(!any((grepl(pattern="[[:digit:]]", cell.ref)&grepl(pattern="[[:alpha:]]", cell.ref)))){
data<-cell.ref
} else if(any(is.na(cell.ref))){
data<-NA
} else if (field=="Date"){
data<-tryCatch(readxl::read_excel(path=excel.file,sheet =format,range=cell.ref, col_types = "date", col_names=FALSE)[[1]]%>% as.character, error=function(e) return(NA))
} else{
#Define rows
rows<-gsub(pattern="[[:alpha:]]", "", x=cell.ref)%>% unique()%>%
strsplit(., split = ":")%>% unlist()%>% as.numeric
rows<-seq(min(rows), max(rows))
#Define cells
cols<-strsplit(cell.ref, split = ":")%>% unlist() %>% openxlsx::convertFromExcelRef() %>% unique()
#Read in row/column specific data from R
data<-tryCatch(openxlsx::read.xlsx(excel.file, sheet=format, rows=rows, cols=cols, colNames=FALSE, skipEmptyRows=FALSE)%>% unlist(),
warning=function(w) return(NA))
}
return(data)
}
#'@export
#'@rdname legacy.format
build.header<-function(excel.file, reference.tall, format){
#Build Header Data Frame
header.fields<-reference.tall$FieldName[reference.tall$Table=="Header"&reference.tall$format==format]
#Build Header Data Frame
header.data<-data.frame(FieldName=header.fields,
value=sapply(X=header.fields, FUN=function(f=X){
print(f)
data<-map.excel(excel.file = excel.file, format = format, reference.tall=reference.tall,field=f)
assign(paste(f), data)
})) %>%
#Spread so that the response values are a row
tidyr::spread(key = FieldName, value=value)%>% dplyr::mutate(excel.file=excel.file)
#Return Header Data
return(header.data)
}
#'@export
#'@rdname legacy.format
#Build Detail Table
build.detail<-function(excel.file, reference.tall, format){
detail.fields<-reference.tall$FieldName[reference.tall$Table=="Detail"&reference.tall$format==format]
#Build data frame
detail.data<-lapply(X=detail.fields, FUN=function(f=X){
print(f)
df=data.frame(data=map.excel(excel.file = excel.file,  format = format, reference.tall=reference.tall,field=f)%>% as.character(),
FieldName=f) %>% dplyr::mutate(id=1:n(), excel.file=excel.file)
df})%>%
do.call(rbind, .) %>%
#Spread so that the response values are a row
tidyr::spread(key = FieldName, value=data)%>% dplyr::select(-id)
}
#'@export
#'@rdname legacy.format
#'
# join.header.detail<-function(excel.file, reference.tall, format){
#   lapply(X=formats, FUN=function(X){
#   #Gather header and detail file
#   header<-build.header(excel.file=excel.file,  reference.tall=reference.tall, format = X)
#   detail<-build.detail(excel.file=excel.file,  reference.tall=reference.tall, format = X)
#   #Join header and detail
#   dplyr::left_join(header, detail)
#
# })%>% do.call(rbind, .)
# }
#Put it all together for an import function
xlsx2R<-function(folder, reference, out){
#Build reference tall data frame
reference.tall<-reference.tall(reference=reference)
files<-list.files(folder, full.names = TRUE, recursive=TRUE)%>% subset(grepl(pattern = ".xlsx$", x=.)&!grepl(pattern = "~", x=.))
if(file.exists(out)){
read.files<-read.csv(out) %>% dplyr::select(excel.file)%>% unique()
#Remove files that have already been read
files<-files[!files %in% read.files$excel.file]
}
#For each excel file in the folder, pull the relevant data
lapply(X=files, FUN=function(X){
format<-openxlsx::getSheetNames(X) %>% subset(. %in% unique(reference.tall$format))
#If the result of format is a character string, then gather header and detail file
if(length(format)>0){
print(X)
#Gather header and detail file
header<-build.header(excel.file=X,  reference.tall=reference.tall, format = format)
detail<-build.detail(excel.file=X,  reference.tall=reference.tall, format = format)
#Join header and detail
header.detail<-dplyr::left_join(header, detail) %>% dplyr::mutate(Format=format)
#save the output to a csv
if(!file.exists(out)){
write.table(header.detail, out, append=FALSE, col.names = TRUE, row.names = FALSE, sep=",")
} else {
write.table(header.detail, out, append=TRUE, col.names = FALSE, row.names = FALSE, sep=",")
}
} else{
warning(paste("No valid data for import.", paste(X), "will be ignored", sep=" "))
print(X)
}})
#Return the completed file from the compiled csv
compiled.csv<-read.csv(out, colClasses = "character" ) %>% unique()
#Fix Shrubshape into a single field (if they exist)
if("ShrubShape1" %in% colnames(compiled.csv)){
compiled.csv$ShrubShape<-paste(compiled.csv$ShrubShape1, compiled.csv$ShrubShape2, compiled.csv$ShrubShape3, compiled.csv$ShrubShape4, sep="")%>%
stringr::str_replace_all("NA|Na", "")
compiled.csv<-dplyr::select(compiled.csv, -c(ShrubShape1:ShrubShape4))
}
#Return
return(compiled.csv)
}
install.packages("ggplot2")
library(ggplot2)
version()
Version()
R.Version()
Version
version
R.Version()
version
sizes <- factor(c("small", "large", "large", "small", "medium"))
sizes
sizes <- factor(c("small", "large", "large", "small", "medium"), levels = c("small", "medium", "large"))
sizes
##This script needs to be run after pulling down updates from JohnsHopkins origin or upstream...
##Changes need to be committed to master after running
setwd("~/OneDrive/GitHub/COVID-19app/csse_covid_19_data/csse_covid_19_daily_reports/")
library("dplyr")
library("lubridate")
#Load JohnsHopkinsAll from cloned Johns Hopkins .csv files in /ccse_covid_19_daily_reports/
JohnsHopkinsAll <- list.files(pattern = "*.csv", full.names = TRUE)
JohnsHopkinsAll <- lapply(JohnsHopkinsAll,function(i){
read.csv(i, header=TRUE)
})
JohnsHopkinsAll <- bind_rows(JohnsHopkinsAll)
###Clean JohnsHopkinsAll###
#Clean Dates
Last.Update <- parse_date_time(JohnsHopkinsAll$Last.Update, orders = c("ymd_HMS", "mdy_HM"))
Last_Update <- parse_date_time(JohnsHopkinsAll$Last_Update, orders = c("ymd_HMS", "mdy_HM"))
Last.Update[is.na(Last.Update)] <- Last_Update[!is.na(Last_Update)]
DateTime <- Last.Update
Date <- format(DateTime, "%Y-%m-%d 00:00:00")
Date <- parse_date_time(Date, orders = c("ymd_HMS"))
#Clean Province/State
Province.State <- JohnsHopkinsAll$Province.State
Province_State <- JohnsHopkinsAll$Province_State
Province.State[is.na(Province.State)] <- Province_State[!is.na(Province_State)]
ProvinceState <- Province.State
#Clean Country/Region
Country.Region <- JohnsHopkinsAll$Country.Region
Country_Region <- JohnsHopkinsAll$Country_Region
Country.Region[is.na(Country.Region)] <- Country_Region[!is.na(Country_Region)]
CountryRegion <- Country.Region
#Clean Province/State
Province.State <- JohnsHopkinsAll$Province.State
Province_State <- JohnsHopkinsAll$Province_State
Province.State[is.na(Province.State)] <- Province_State[!is.na(Province_State)]
ProvinceState <- Province.State
#Collect Regular Attributes (Simpler than dates, location, etc...)
Confirmed <- JohnsHopkinsAll$Confirmed
Deaths <- JohnsHopkinsAll$Deaths
Recovered <- JohnsHopkinsAll$Recovered
Active <- JohnsHopkinsAll$Active
FIPS <- JohnsHopkinsAll$FIPS
Admin2 <- JohnsHopkinsAll$Admin2
#Join into new dataframe
JohnsHopkinsAll <- data.frame(Date, DateTime, ProvinceState, CountryRegion, Admin2, FIPS, Confirmed, Active, Deaths, Recovered)
#Write out as updated JohnsHopkinsAll.csv
#This file will be read in by server.R where filtering and analysis will begin
write.csv(JohnsHopkinsAll, "../../ShinyApp/JohnsHopkinsAll.csv")
#Load JohnsHopkinsAll from cloned Johns Hopkins .csv files in /ccse_covid_19_daily_reports/
JohnsHopkinsAll <- list.files(pattern = "*.csv", full.names = TRUE)
